{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluation for Assistant API\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dataset chosen is the famous `hotspotqa` which is commonly used to evaluate QA and context understanding. \n",
    "\n",
    "This notebook is targeted at following goals:\n",
    "\n",
    "1. Investigate performance of opensource solutions with `mixtral-7bx8` and `LLMCompiler` as function calling strategy.\n",
    "2. Compares differences between the above solution and the official OpenAI Assistant API (with gpt-3.5-turbo).   \n"
   ],
   "id": "693c7feb77ce3e1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:43:27.761257Z",
     "start_time": "2024-05-19T14:43:26.123948Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install datasets numpy langchain",
   "id": "e9f6aec51818b5f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (2.19.1)\r\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (1.26.4)\r\n",
      "Requirement already satisfied: langchain in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (0.1.19)\r\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from datasets) (3.14.0)\r\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from datasets) (16.1.0)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from datasets) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from datasets) (2.2.2)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from datasets) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from datasets) (4.66.4)\r\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from datasets) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\r\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from datasets) (3.9.5)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from datasets) (0.23.0)\r\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from datasets) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from datasets) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from langchain) (1.4.52)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from langchain) (0.6.5)\r\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from langchain) (0.0.38)\r\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from langchain) (0.1.52)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from langchain) (0.0.1)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from langchain) (0.1.56)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from langchain) (2.7.1)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from langchain) (8.3.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.18.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/instinct-lab/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\r\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:43:27.831263Z",
     "start_time": "2024-05-19T14:43:27.762819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "903811e1ec7b9d9d",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prepare dataset\n",
    "\n",
    "Only hard level questions in [validation split](https://huggingface.co/datasets/scholarly-shadows-syndicate/hotpotqa_with_qa_gpt35/viewer/default/validation) is used in this notebook. "
   ],
   "id": "ba4f85e4ae4f417"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:43:32.034233Z",
     "start_time": "2024-05-19T14:43:27.832304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"scholarly-shadows-syndicate/hotpotqa_with_qa_gpt35\", split=\"validation\", streaming=True).filter(lambda x: x[\"level\"] == \"hard\")\n"
   ],
   "id": "ba34d4d65079d246",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Benchmark runner\n",
    "\n",
    "* `BenchmarkRunner.run`: load validation dataset and run the QA task, and then save the result to `output_file_path`.\n",
    "* `Benchmarkrunner.get_metrics`: load runner result from `output_file_path` and calculate metric data.\n",
    "\n",
    "Only one search tool based on TAVILY API is used during this test and I borrow it from langchain. So make sure that `TAVILY_API_KEY` is set in env variables."
   ],
   "id": "8200a33105129fb2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:43:36.154832Z",
     "start_time": "2024-05-19T14:43:32.035765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from langchain.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "# from langchain.tools.tavily_search import TavilySearchResults\n",
    "# from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "# from langchain.agents import load_tools\n",
    "\n",
    "# tools = load_tools([\"google-serper\"])\n",
    "\n",
    "# tavily_tool = TavilySearchResults(api_wrapper=TavilySearchAPIWrapper(), max_results=5)\n",
    "# search_tool_schema = convert_to_openai_function(tools[0])\n",
    "# search_tool_schema[\"name\"] = \"search\"\n",
    "# print(search_tool_schema)\n",
    "\n",
    "# result = tools[0].run(\"country with most populations\")\n",
    "# print(result)\n",
    "\n",
    "# search_result = \"\\n\".join([item[\"content\"] for item in result])\n",
    "\n",
    "# search_result\n",
    "\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from tool.wikipedia import ReActWikipedia, DocstoreExplorer\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional, Type, Any\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"entity to search for on Wikipedia, e.g., Mount Everest, cheetah, San Francisco, etc.\")\n",
    "\n",
    "\n",
    "class WikiSearch(BaseTool):\n",
    "    name = \"search\"\n",
    "    description = \"useful for when you need to answer questions about current events\"\n",
    "    args_schema: Type[BaseModel] = SearchInput\n",
    "    \n",
    "    web_searcher = ReActWikipedia()\n",
    "    docstore = DocstoreExplorer(web_searcher)\n",
    "\n",
    "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        return self.docstore.search(query)\n",
    "\n",
    "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        return await self.docstore.asearch(query)\n",
    "\n",
    "\n",
    "wiki_search = WikiSearch()\n",
    "print(wiki_search.name)\n",
    "print(wiki_search.description)\n",
    "print(wiki_search.args)\n",
    "print(wiki_search.invoke(\"Corliss Archer in Kiss and Tell\"))\n",
    "print(wiki_search.run({\"query\": \"Mount Everest\"}))"
   ],
   "id": "f37023d36a1fe60d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n",
      "useful for when you need to answer questions about current events\n",
      "{'query': {'title': 'Query', 'description': 'entity to search for on Wikipedia, e.g., Mount Everest, cheetah, San Francisco, etc.', 'type': 'string'}}\n",
      "==== Corliss Archer in Kiss and Tell\n",
      "Could not find Corliss Archer in Kiss and Tell. Similar: ['Corliss Archer', 'A Kiss for Corliss', 'Kiss and Tell (1945 film)', 'Kiss and Tell (play)', 'Meet Corliss Archer'].\n",
      "Kiss and Tell is a 1945 American comedy film starring then 17-year-old Shirley Temple as Corliss Archer. In the film, two teenage girls cause their respective parents much concern when they start to become interested in boys. The parents' bickering about which girl is the worse influence causes more problems than it solves.[2]. The movie was based on the Broadway play Kiss and Tell, which was based on the Corliss Archer short stories. The stories, play and movie were all written by F.\n",
      "Kiss and Tell is a 1945 American comedy film starring then 17-year-old Shirley Temple as Corliss Archer. In the film, two teenage girls cause their respective parents much concern when they start to become interested in boys. The parents' bickering about which girl is the worse influence causes more problems than it solves.[2]. The movie was based on the Broadway play Kiss and Tell, which was based on the Corliss Archer short stories. The stories, play and movie were all written by F.\n",
      "==== Mount Everest\n",
      "Mount Everest[3] is Earth's highest mountain above sea level, located in the Mahalangur Himal sub-range of the Himalayas. The China–Nepal border runs across its summit point.[4] Its elevation (snow height) of 8,848.86 m (29,031 ft 8+1⁄2 in) was most recently established in 2020 by the Chinese and Nepali authorities.[5][6]. Mount Everest attracts many climbers, including highly experienced mountaineers. There are two main climbing routes, one approaching the summit from the southeast in Nepal (known as the \"standard route\") and the other from the north in Tibet. While not posing substantial technical climbing challenges on the standard route, Everest presents dangers such as altitude sickness, weather, and wind, as well as hazards from avalanches and the Khumbu Icefall.\n",
      "Mount Everest[3] is Earth's highest mountain above sea level, located in the Mahalangur Himal sub-range of the Himalayas. The China–Nepal border runs across its summit point.[4] Its elevation (snow height) of 8,848.86 m (29,031 ft 8+1⁄2 in) was most recently established in 2020 by the Chinese and Nepali authorities.[5][6]. Mount Everest attracts many climbers, including highly experienced mountaineers. There are two main climbing routes, one approaching the summit from the southeast in Nepal (known as the \"standard route\") and the other from the north in Tibet. While not posing substantial technical climbing challenges on the standard route, Everest presents dangers such as altitude sickness, weather, and wind, as well as hazards from avalanches and the Khumbu Icefall.\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:43:36.227735Z",
     "start_time": "2024-05-19T14:43:36.155458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import logging\n",
    "import numpy as np\n",
    "import time\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def normalize_answer(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def compare_answer(answer: str, label: str):\n",
    "    \"\"\"Compare the answer (from Agent) and label (GT).\n",
    "    Label can be either a string or a number.\n",
    "    If label is a number, we allow 10% margin.\n",
    "    Otherwise, we do the best-effort string matching.\n",
    "    \"\"\"\n",
    "    if answer is None:\n",
    "        return False\n",
    "\n",
    "    # see if label is a number, e.g. \"1.0\" or \"1\"\n",
    "    if is_number(label):\n",
    "        label = float(label)\n",
    "        # try cast answer to float and return false if it fails\n",
    "        try:\n",
    "            answer = float(answer)\n",
    "        except:\n",
    "            return False\n",
    "        # allow 10% margin\n",
    "        if label * 0.9 < answer < label * 1.1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    else:\n",
    "        label = normalize_answer(label)\n",
    "        answer = normalize_answer(answer)\n",
    "        return answer == label\n",
    "\n",
    "\n",
    "class BenchmarkRunner:\n",
    "    \n",
    "    thread_history = []\n",
    "    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 openai_client: OpenAI, \n",
    "                 model_name: str, \n",
    "                 instructions: str,\n",
    "                 output_file_path: str = \"output/hotqa_result.json\"):\n",
    "        \"\"\"\n",
    "        Benchmark an agent with an OpenAI client.\n",
    "        :param openai_client: \n",
    "        :param model_name: \n",
    "        :param instructions: useful to provide examples for joiner of LLMCompiler\n",
    "        :param output_file_path: \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.logger = logging.getLogger(\"BenchmarkRunner\")\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "        self.client = openai_client\n",
    "        self.output_file_path = output_file_path\n",
    "        self.search_tool = wiki_search\n",
    "        self.model_name = model_name\n",
    "        self.assistant = None\n",
    "        self.instructions = instructions\n",
    "        try:\n",
    "            self.result = json.load(open(output_file_path)) if os.path.exists(output_file_path) else []\n",
    "        except:\n",
    "            self.result = []\n",
    "\n",
    "    def cleanup(self):\n",
    "        for thread_id in self.thread_history:\n",
    "            self.logger.info(f\"delete thread {thread_id}\")\n",
    "            self.client.beta.threads.delete(thread_id=thread_id)\n",
    "        if self.assistant:\n",
    "            self.logger.info(f\"delete assistant {self.assistant.id}\")\n",
    "            self.client.beta.assistants.delete(assistant_id=self.assistant.id)\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        try:\n",
    "            self.cleanup()\n",
    "        except Exception as e:\n",
    "            self.logger.error(e)\n",
    "\n",
    "    def run(self):\n",
    "        self.logger.info(f\"run started\")\n",
    "        for item in load_dataset(\"scholarly-shadows-syndicate/hotpotqa_with_qa_gpt35\", split=\"validation\", streaming=True).filter(lambda x: x[\"level\"] == \"hard\"):\n",
    "            self.logger.info(f\"item id={item['id']}\")   \n",
    "            self.assistant = client.beta.assistants.create(\n",
    "                name=\"benchmark-runner\",\n",
    "                model=self.model_name,\n",
    "                instructions=self.instructions,\n",
    "                tools=[{\"type\": \"function\", \"function\": convert_to_openai_function(self.search_tool)}]\n",
    "            )\n",
    "            self.logger.info(f\"assistant id: {self.assistant.id}\")\n",
    "            \n",
    "            run = self.client.beta.threads.create_and_run(\n",
    "                assistant_id=self.assistant.id,\n",
    "                thread={\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"user\", \"content\": item[\"question\"]}\n",
    "                    ]\n",
    "                },\n",
    "                stream=False)\n",
    "            self.logger.info(f\"run, id={run.id}, thread_id={run.thread_id}\")\n",
    "\n",
    "            self.thread_history.append(run.thread_id)\n",
    "            result_item = {\n",
    "                \"ok\": False,\n",
    "                \"answer\": \"\",\n",
    "                \"truth\": item[\"answer\"], \n",
    "                \"id\": item[\"id\"],\n",
    "                \"rt\": 0\n",
    "            }\n",
    "            while True:\n",
    "                ts_1 = time.time()\n",
    "                run = self.client.beta.threads.runs.retrieve(thread_id=run.thread_id, run_id=run.id)\n",
    "                if run.status == \"queued\" or run.status == \"in_progress\":\n",
    "                    time.sleep(1)\n",
    "                elif run.status == \"requires_action\":\n",
    "                    tool_messages = []\n",
    "                    for call in run.required_action.submit_tool_outputs.tool_calls:\n",
    "                        self.logger.info(f\"got tool call: {call.json()}\")\n",
    "                        if call.type == \"function\" and call.function.name == self.search_tool.name:\n",
    "                            tool_result  = self.search_tool.run(json.loads(call.function.arguments))\n",
    "                            tool_messages.append({\"tool_call_id\": call.id, \"output\": tool_result})\n",
    "                        else:\n",
    "                            raise RuntimeError(f\"Unknown tool call occurred, function name {call.function.name}\")\n",
    "                    self.logger.info(f\"len(tool_messages)={len(tool_messages)}, len(tool_calls)={len(run.required_action.submit_tool_outputs.tool_calls)}\")\n",
    "                    if len(tool_messages) == len(run.required_action.submit_tool_outputs.tool_calls):\n",
    "                        run = self.client.beta.threads.runs.submit_tool_outputs(thread_id=run.thread_id, run_id=run.id, tool_outputs=tool_messages)\n",
    "                        self.logger.info(f\"run object status after submit: {run.status}\")\n",
    "                    else:\n",
    "                        raise RuntimeError(\"Not every call is responded.\")\n",
    "                        # break\n",
    "                elif run.status == \"completed\": \n",
    "                    messages = self.client.beta.threads.messages.list(thread_id=run.thread_id, run_id=run.id, order=\"asc\")\n",
    "                    result_item[\"ok\"] = True\n",
    "                    result_item[\"answer\"] = messages.data[-1].content[0].text.value\n",
    "                    self.logger.info(\"begin printing trajectory =============================\")\n",
    "                    for message in messages.data:\n",
    "                        self.logger.info(f\"{message.role}: {message.content[0].text.value}\")\n",
    "                    self.logger.info(\"finish printing trajectory =============================\")\n",
    "                    break\n",
    "                else:\n",
    "                    self.logger.error(f\"run is in other terminal status: {run.to_json()}\")\n",
    "                    break    \n",
    "            \n",
    "            result_item[\"rt\"] = time.time() - ts_1\n",
    "            self.result.append(result_item)\n",
    "            self.logger.info(f\"id={result_item['id']}, ok={result_item['ok']}\")\n",
    "            \n",
    "            # write down the result\n",
    "            with open(self.output_file_path, \"w\") as output_json:\n",
    "                json.dump(self.result, output_json)\n",
    "        \n",
    "            \n",
    "    def get_metrics(self):\n",
    "        with open(self.output_file_path, \"r\") as result_file:\n",
    "            result = json.load(result_file)\n",
    "            acc = np.average([compare_answer(item[\"answer\"], item[\"truth\"]) for item in result])\n",
    "            rt_avg = np.average([item[\"rt\"] for item in result])\n",
    "            rt_std = np.std([item[\"rt\"] for item in result])\n",
    "            success_rate = np.average([1 if item[\"ok\"] else 0 for item in result])\n",
    "            \n",
    "            logging.info(f\"Success rate: {success_rate}\")\n",
    "            logging.info(f\"Accuracy: {acc}\")\n",
    "            logging.info(f\"Latency: {rt_avg} +/- {rt_std}\")\n",
    "            \n",
    "            return success_rate, acc, rt_avg, rt_std\n",
    "\n",
    "\n",
    "\n",
    "DEFAULT_JOINER_INSTRUCTIONS_WITH_EXAMPLES = r'''Here are some examples with a tool named \"search\":\n",
    "\n",
    "Question: Which magazine was started first Arthur's Magazine or First for Women?\n",
    "search({\"query\": \"Arthur's Magazine\"})\n",
    "Observation: Arthur's Magazine (1844-1846) was an American literary periodical published in Philadelphia in the 19th century.\n",
    "search({\"query\": \"First for Women\"})\n",
    "Observation: First for Women is a woman's magazine published by Bauer Media Group in the USA.[1] The magazine was started in 1989.\n",
    "Thought: Arthur's Magazine was started in 1844. First for Women was started in 1989. 1844 (Arthur's Magazine) < 1989 (First for Women), so Arthur's Magazine was started first.\n",
    "Action: Finish(Arthur's Magazine)\n",
    "<END_OF_RESPONSE>\n",
    "\n",
    "Question: Were Pavel Urysohn and Leonid Levin known for the same type of work?\n",
    "search({\"query\": \"Pavel Urysohn\"})\n",
    "Observation: Pavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet mathematician who is best known for his contributions in dimension theory.\n",
    "search(Leonid Levin)\n",
    "Observation: Leonid Anatolievich Levin is a Soviet-American mathematician and computer scientist.\n",
    "Thought: Pavel Urysohn is a mathematician. Leonid Levin is a mathematician and computer scientist. So Pavel Urysohn and Leonid Levin have the same type of work.\n",
    "Action: Finish(yes)\n",
    "<END_OF_RESPONSE>\n",
    "\n",
    "Question: What profession does Nicholas Ray and Elia Kazan have in common?\n",
    "Observation: Nicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16, 1979) was an American film director best known for the 1955 film Rebel Without a Cause.\n",
    "Observation: Elia Kazan was an American film and theatre director.\n",
    "Thought: Professions of Nicholas Ray are director, screenwriter, and actor. Professions of Elia Kazan are director. So profession Nicholas Ray and Elia Kazan have in common is director.\n",
    "Action: Finish(director)\n",
    "<END_OF_RESPONSE>'''"
   ],
   "id": "22e9c051a92eef73",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Benchmarks\n",
    "\n",
    "\n",
    "## With `mini-assistant`\n",
    "\n",
    "Start mini assistant server.\n",
    "\n",
    "* `llm_compiler` is used for agent execution\n",
    "* `mixtral 7bx8` is hosted by vLLM. Please make sure you have set up `HUGGING_FACE_HUB_TOKEN` env for vLLM.\n",
    "\n",
    "vLLM shell command using docker:\n",
    "\n",
    "```shell\n",
    "docker run --runtime nvidia --gpus all \\\n",
    "    -v /workspace/dropbox/huggingface_models:/root/.cache/huggingface \\\n",
    "    --env \"HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}\" \\\n",
    "    -p 8000:8000 \\\n",
    "    --ipc=host \\\n",
    "    vllm/vllm-openai:latest \\\n",
    "    --model TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ \\\n",
    "    --quantization marlin \\\n",
    "    --dtype=float16\n",
    "```\n",
    "\n",
    "mini-assistant shell command:\n",
    "\n",
    "```shell\n",
    "mkdir -p /tmp/mini-assistant-db\n",
    "mkdir -p /tmp/mini-assistant-files\n",
    "mini-assistant --db_file_path /tmp/assistant_eval.db \\\n",
    "  --file_store_path /tmp/mini-assistant-files \\\n",
    "  --agent_executor_type=llm_compiler \\\n",
    "  --model_provider=openai \\\n",
    "  --openai_port=8000 \\\n",
    "  --openai_host=192.168.0.134 \\\n",
    "  --openai_protocol=http \\\n",
    "  --port=9091 \\\n",
    "  --verbose\n",
    "```\n",
    "\n",
    "Please make sure to make necessary modification to `--openai_host`, `--openai_port` and `--openai_protocol` according to your own vLLM setup.  \n",
    "\n",
    "\n",
    "And kick off benchmarks in python script:"
   ],
   "id": "a1591179d0e975e5"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-19T14:43:36.228775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if True:\n",
    "    if not os.path.exists(\"./output\"):\n",
    "        os.mkdir(\"./output\")\n",
    "    client = OpenAI(base_url=\"http://localhost:9091/v1\")\n",
    "    with BenchmarkRunner(openai_client=client, instructions=DEFAULT_JOINER_INSTRUCTIONS_WITH_EXAMPLES, model_name=\"TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ\", output_file_path=\"./output/miniassistant_result.json\") as benchmark_runner:\n",
    "        benchmark_runner.run()\n",
    "        benchmark_runner.get_metrics()\n",
    "    "
   ],
   "id": "8642baf2b49664bc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:BenchmarkRunner:run started\n",
      "INFO:BenchmarkRunner:item id=5a8b57f25542995d1e6f1371\n",
      "INFO:httpx:HTTP Request: POST http://localhost:9091/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "INFO:BenchmarkRunner:assistant id: asst_760414379454758912\n",
      "INFO:httpx:HTTP Request: POST http://localhost:9091/v1/threads/runs \"HTTP/1.1 200 OK\"\n",
      "INFO:BenchmarkRunner:run, id=run_760414379530256384, thread_id=thread_760414379530256385\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414379530256385/runs/run_760414379530256384 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414379530256385/runs/run_760414379530256384 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414379530256385/runs/run_760414379530256384 \"HTTP/1.1 200 OK\"\n",
      "INFO:BenchmarkRunner:got tool call: {\"id\":\"call_760414387746897920\",\"function\":{\"arguments\":\"{\\\"query\\\": \\\"Scott Derrickson\\\"}\",\"name\":\"search\"},\"type\":\"function\"}\n",
      "INFO:BenchmarkRunner:got tool call: {\"id\":\"call_760414387751092224\",\"function\":{\"arguments\":\"{\\\"query\\\": \\\"Ed Wood\\\"}\",\"name\":\"search\"},\"type\":\"function\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Scott Derrickson\n",
      "Scott Derrickson (born July 16, 1966) is an American filmmaker. He is best known for his work in the horror genre, directing films such as The Exorcism of Emily Rose (2005), Sinister (2012) and The Black Phone (2021). He is also known for the superhero film Doctor Strange (2016), based on the Marvel Comics character.. Scott Derrickson grew up in Denver, Colorado. He graduated from Biola University with a B.A.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:BenchmarkRunner:len(tool_messages)=2, len(tool_calls)=2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:9091/v1/threads/thread_760414379530256385/runs/run_760414379530256384/submit_tool_outputs \"HTTP/1.1 200 OK\"\n",
      "INFO:BenchmarkRunner:run object status after submit: queued\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414379530256385/runs/run_760414379530256384 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Ed Wood\n",
      "Edward Davis Wood Jr. (October 10, 1924 – December 10, 1978) was an American filmmaker, actor, screenwriter, and pulp novelist.. In the 1950s, Wood directed several low-budget science fiction, crime and horror films that later became cult classics, notably Glen or Glenda (1953), Jail Bait (1954), Bride of the Monster (1955), Plan 9 from Outer Space (1957) and Night of the Ghouls (1959).[1] In the 1960s and 1970s, he moved towards sexploitation and pornographic films such as The Sinister Urge (1960), Orgy of the Dead (1965) and Necromania (1971), and wrote over 80 lurid pulp crime and sex novels.. Notable for their campy aesthetics, technical errors, unsophisticated special effects, use of poorly-matched stock footage, eccentric casts, idiosyncratic stories and non sequitur dialogue, Wood's films remained largely obscure until he was posthumously awarded a Golden Turkey Award for Worst Director of All Time in 1980, renewing public interest in his life and work.[2]. Following the publication of Rudolph Grey's 1992 oral biography Nightmare of Ecstasy: The Life and Art of Edward D.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414379530256385/runs/run_760414379530256384 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414379530256385/runs/run_760414379530256384 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414379530256385/runs/run_760414379530256384 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414379530256385/messages?order=asc&run_id=run_760414379530256384 \"HTTP/1.1 200 OK\"\n",
      "INFO:BenchmarkRunner:begin printing trajectory =============================\n",
      "INFO:BenchmarkRunner:user: Were Scott Derrickson and Ed Wood of the same nationality?\n",
      "INFO:BenchmarkRunner:assistant: same nationality\n",
      "INFO:BenchmarkRunner:finish printing trajectory =============================\n",
      "INFO:BenchmarkRunner:id=5a8b57f25542995d1e6f1371, ok=True\n",
      "INFO:BenchmarkRunner:item id=5a8c7595554299585d9e36b6\n",
      "INFO:httpx:HTTP Request: POST http://localhost:9091/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "INFO:BenchmarkRunner:assistant id: asst_760414410966564864\n",
      "INFO:httpx:HTTP Request: POST http://localhost:9091/v1/threads/runs \"HTTP/1.1 200 OK\"\n",
      "INFO:BenchmarkRunner:run, id=run_760414411037868032, thread_id=thread_760414411037868033\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414411037868033/runs/run_760414411037868032 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414411037868033/runs/run_760414411037868032 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414411037868033/runs/run_760414411037868032 \"HTTP/1.1 200 OK\"\n",
      "INFO:BenchmarkRunner:got tool call: {\"id\":\"call_760414417560010752\",\"function\":{\"arguments\":\"{\\\"query\\\": \\\"Corliss Archer in Kiss and Tell\\\"}\",\"name\":\"search\"},\"type\":\"function\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Corliss Archer in Kiss and Tell\n",
      "Could not find Corliss Archer in Kiss and Tell. Similar: ['Corliss Archer', 'A Kiss for Corliss', 'Kiss and Tell (1945 film)', 'Kiss and Tell (play)', 'Meet Corliss Archer'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:BenchmarkRunner:len(tool_messages)=1, len(tool_calls)=1\n",
      "INFO:httpx:HTTP Request: POST http://localhost:9091/v1/threads/thread_760414411037868033/runs/run_760414411037868032/submit_tool_outputs \"HTTP/1.1 200 OK\"\n",
      "INFO:BenchmarkRunner:run object status after submit: queued\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414411037868033/runs/run_760414411037868032 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiss and Tell is a 1945 American comedy film starring then 17-year-old Shirley Temple as Corliss Archer. In the film, two teenage girls cause their respective parents much concern when they start to become interested in boys. The parents' bickering about which girl is the worse influence causes more problems than it solves.[2]. The movie was based on the Broadway play Kiss and Tell, which was based on the Corliss Archer short stories. The stories, play and movie were all written by F.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414411037868033/runs/run_760414411037868032 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414411037868033/runs/run_760414411037868032 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414411037868033/runs/run_760414411037868032 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414411037868033/runs/run_760414411037868032 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414411037868033/runs/run_760414411037868032 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414411037868033/messages?order=asc&run_id=run_760414411037868032 \"HTTP/1.1 200 OK\"\n",
      "INFO:BenchmarkRunner:begin printing trajectory =============================\n",
      "INFO:BenchmarkRunner:user: What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\n",
      "INFO:BenchmarkRunner:assistant: Unknown\n",
      "INFO:BenchmarkRunner:finish printing trajectory =============================\n",
      "INFO:BenchmarkRunner:id=5a8c7595554299585d9e36b6, ok=True\n",
      "INFO:BenchmarkRunner:item id=5a85ea095542994775f606a8\n",
      "INFO:httpx:HTTP Request: POST http://localhost:9091/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "INFO:BenchmarkRunner:assistant id: asst_760414461331767296\n",
      "INFO:httpx:HTTP Request: POST http://localhost:9091/v1/threads/runs \"HTTP/1.1 200 OK\"\n",
      "INFO:BenchmarkRunner:run, id=run_760414461411459072, thread_id=thread_760414461411459073\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414461411459073/runs/run_760414461411459072 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414461411459073/runs/run_760414461411459072 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414461411459073/runs/run_760414461411459072 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:9091/v1/threads/thread_760414461411459073/runs/run_760414461411459072 \"HTTP/1.1 200 OK\"\n",
      "INFO:BenchmarkRunner:got tool call: {\"id\":\"call_760414471163215872\",\"function\":{\"arguments\":\"{\\\"query\\\": \\\"science fantasy young adult series in first person\\\"}\",\"name\":\"search\"},\"type\":\"function\"}\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "if False:\n",
    "    if not os.path.exists(\"./output\"):\n",
    "        os.mkdir(\"./output\")\n",
    "    client = OpenAI()\n",
    "    with BenchmarkRunner(openai_client=client, instructions=DEFAULT_JOINER_INSTRUCTIONS_WITH_EXAMPLES,  model_name=\"gpt-3.5-turbo\", output_file_path=\"./output/openai_result.json\") as benchmark_runner:\n",
    "        # benchmark_runner.run()\n",
    "        benchmark_runner.get_metrics()"
   ],
   "id": "8e103a1a13e346e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4168e98a6825ce01",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
